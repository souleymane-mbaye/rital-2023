{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4c3d011d",
      "metadata": {
        "id": "4c3d011d"
      },
      "source": [
        "## --- Generate text with a recurrent neural network (Pytorch) ---\n",
        "### (Mostly Read & Run)\n",
        "\n",
        "The goal is to replicate the (famous) experiment from [Karpathy's blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "\n",
        "To learn to generate text, we train a recurrent neural network to do the following task:\n",
        "\n",
        "Given a \"chunk\" of text: `this is random text`\n",
        "\n",
        "the goal of the network is to predict each character in **`his is random text` ** sequentially given the following sequential input **`this is random tex`**:\n",
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "905e7491",
      "metadata": {
        "id": "905e7491"
      },
      "source": [
        "Input ->  Output\n",
        "--------------\n",
        "T    ->    H\n",
        "H    ->    I\n",
        "I    ->    S\n",
        "S    ->    \" \"\n",
        "\" \"  ->    I\n",
        "I    ->    S\n",
        "S    ->    \" \"\n",
        "[...]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7adb3f04",
      "metadata": {
        "id": "7adb3f04"
      },
      "source": [
        "\n",
        "## Load text (dataset/input.txt)\n",
        "\n",
        "Before building training batch, we load the full text in RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b8d03d20",
      "metadata": {
        "id": "b8d03d20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74aa1d0b-326f-4c6d-9883-f7c69cc574b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-17 15:02:14--  https://thome.isir.upmc.fr/classes/RITAL/input.txt\n",
            "Resolving thome.isir.upmc.fr (thome.isir.upmc.fr)... 134.157.18.247\n",
            "Connecting to thome.isir.upmc.fr (thome.isir.upmc.fr)|134.157.18.247|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M   858KB/s    in 1.3s    \n",
            "\n",
            "2023-02-17 15:02:17 (858 KB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://thome.isir.upmc.fr/classes/RITAL/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1fa52e79",
      "metadata": {
        "id": "1fa52e79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c816b0dc-a943-4caa-aa90-62b080f22950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ],
      "source": [
        "! pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "890c249b",
      "metadata": {
        "id": "890c249b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7b48b4-8b5d-4c51-af38-26dddf94e9ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_len = 1115394\n"
          ]
        }
      ],
      "source": [
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "file = unidecode.unidecode(open('./input.txt').read()) #clean text => only ascii\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af54275",
      "metadata": {
        "id": "4af54275"
      },
      "source": [
        "## 2: Helper functions:\n",
        "\n",
        "We have a text and we want to feed batch of chunks to a neural network:\n",
        "\n",
        "one chunk  A,B,C,D,E\n",
        "[input] A,B,C,D -> B,C,D,E [output]\n",
        "\n",
        "Note: we will use an embedding layer instead of a one-hot encoding scheme.\n",
        "\n",
        "for this, we have 3 functions:\n",
        "\n",
        "- One to get a random str chunk of size `chunk_len` : `random_chunk` \n",
        "- One to turn a chunk into a tensor of size `(1,chunk_len)` coding for each characters : `char_tensor`\n",
        "- One to return random input and output chunks of size `(batch_size,chunk_len)` : `random_training_set`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e1f68d51",
      "metadata": {
        "id": "e1f68d51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c4753e-b72d-4a3d-e09e-75ca86a11351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[96, 96, 38, 50, 53, 44, 50, 47, 36, 49],\n",
            "        [60, 50, 53, 46, 77, 96, 44, 94, 25, 27],\n",
            "        [17, 18, 29, 75, 96, 96, 53, 50, 48, 40],\n",
            "        [28, 14, 14, 12, 17, 94, 34, 24, 30, 82]]), tensor([[96, 38, 50, 53, 44, 50, 47, 36, 49, 56],\n",
            "        [50, 53, 46, 77, 96, 44, 94, 25, 27, 18],\n",
            "        [18, 29, 75, 96, 96, 53, 50, 48, 40, 50],\n",
            "        [14, 14, 12, 17, 94, 34, 24, 30, 82, 96]]))\n"
          ]
        }
      ],
      "source": [
        "import time, math\n",
        "\n",
        "\n",
        "#Get a piece of text\n",
        "def random_chunk(chunk_len):\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(1,len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[0,c] = all_characters.index(string[c])\n",
        "    return tensor\n",
        "\n",
        "\n",
        "#Turn a piece of text in train/test\n",
        "def random_training_set(chunk_len=200, batch_size=8):\n",
        "    chunks = [random_chunk(chunk_len) for _ in range(batch_size)]\n",
        "    inp = torch.cat([char_tensor(chunk[:-1]) for chunk in chunks],dim=0)\n",
        "    target = torch.cat([char_tensor(chunk[1:]) for chunk in chunks],dim=0)\n",
        "    \n",
        "    return inp, target\n",
        "\n",
        "print(random_training_set(10,4))  ## should return 8 chunks of 10 letters. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "141dad88",
      "metadata": {
        "id": "141dad88"
      },
      "source": [
        "## The actual RNN model (only thing to complete):\n",
        "\n",
        "It should be composed of three distinct modules:\n",
        "\n",
        "- an [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) (n_characters, hidden_size)\n",
        "\n",
        "```\n",
        "nn.Embedding(len_dic,size_vec)\n",
        "```\n",
        "- a [recurrent](https://pytorch.org/docs/stable/nn.html#recurrent-layers) layer (hidden_size, hidden_size)\n",
        "```\n",
        "nn.RNN(in_size,out_size) or nn.GRU() or nn.LSTM() => rnn_cell parameter\n",
        "```\n",
        "- a [prediction](https://pytorch.org/docs/stable/nn.html#linear) layer (hidden_size, output_size)\n",
        "\n",
        "```\n",
        "nn.Linear(in_size,out_size)\n",
        "```\n",
        "=> Complete the `init` function code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8d838e47",
      "metadata": {
        "id": "8d838e47"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as f\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_char, hidden_size, output_size, n_layers=1,rnn_cell=nn.RNN):\n",
        "        \"\"\"\n",
        "        Create the network\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.n_char = n_char\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        #  (batch,chunk_len) -> (batch, chunk_len, hidden_size)  \n",
        "        self.embed = nn.Embedding(self.n_char,self.hidden_size )  ####\n",
        "        \n",
        "        # (batch, chunk_len, hidden_size)  -> (batch, chunk_len, hidden_size)  \n",
        "        self.rnn = nn.RNN(self.n_char, self.output_size) ####\n",
        "        \n",
        "        #(batch, chunk_len, hidden_size) -> (batch, chunk_len, output_size)  \n",
        "        self.predict = nn.Linear(self.n_char,self.output_size) ####\n",
        "    \n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        batched forward: input is (batch > 1,chunk_len)\n",
        "        \"\"\"\n",
        "        input = self.embed(input)\n",
        "        output,_  = self.rnn(input)\n",
        "        output = self.predict(f.tanh(output))\n",
        "        return output\n",
        "    \n",
        "    def forward_seq(self, input,hidden=None):\n",
        "        \"\"\"\n",
        "        not batched forward: input is  (1,chunk_len)\n",
        "        \"\"\"\n",
        "        input = self.embed(input)\n",
        "        output,hidden  = self.rnn(input.unsqueeze(0),hidden)\n",
        "        output = self.predict(f.tanh(output))\n",
        "        return output,hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34643b32",
      "metadata": {
        "collapsed": true,
        "id": "34643b32"
      },
      "source": [
        "## Text generation function\n",
        "\n",
        "Sample text from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4c751d5f",
      "metadata": {
        "id": "4c751d5f"
      },
      "outputs": [],
      "source": [
        "def generate(model,prime_str='A', predict_len=100, temperature=0.8):\n",
        "    prime_input = char_tensor(prime_str).squeeze(0)\n",
        "    hidden = None\n",
        "    predicted = prime_str+\"\"\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "\n",
        "    for p in range(len(prime_str)-1):\n",
        "        _,hidden = model.forward_seq(prime_input[p].unsqueeze(0),hidden)\n",
        "            \n",
        "    #print(hidden.size())\n",
        "    for p in range(predict_len):\n",
        "        output, hidden = model.forward_seq(prime_input[-1].unsqueeze(0), hidden)\n",
        "                # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        #print(output_dist)\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        #print(top_i)\n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        prime_input = torch.cat([prime_input,char_tensor(predicted_char).squeeze(0)])\n",
        "\n",
        "    return predicted\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8783b21d",
      "metadata": {
        "collapsed": true,
        "id": "8783b21d"
      },
      "source": [
        "## Training loop for net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9acbf3af",
      "metadata": {
        "id": "9acbf3af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab999d26-ce43-4099-a1ec-71e9aece8c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0m 3s (100 0%) 2.5052]\n",
            "Whoure wand gast heve avatr whio ghasthe her pl s dat ne ERY:\n",
            "ANG my fatto my I I be n t ble hend casa \n",
            "\n",
            "[0m 6s (200 1%) 2.5544]\n",
            "Whint, longeresin, s d cer y les, s cond fre;\n",
            "Iisthen e nd mperas hepu g ved Bucend, llanther's ber y  \n",
            "\n",
            "[0m 9s (300 1%) 2.4889]\n",
            "Whicu ho wy h\n",
            "BEYou mpr thitoulir'ld ofimee her renour terarsthir: hokiled o men son ngh thinieadortig \n",
            "\n",
            "[0m 12s (400 2%) 2.4934]\n",
            "Whate.\n",
            "Shexn she tathy yof;\n",
            "MAntousinise RED omye th, pre bly.\n",
            "Se tooninoutr, ke thay nd he byon, mis  \n",
            "\n",
            "[0m 15s (500 2%) 2.5407]\n",
            "Whaton, t coloulyode.\n",
            "An hand t tors of tcry ged ans; menie se withord wis he\n",
            "'s hes bld bull whin hik \n",
            "\n",
            "[0m 18s (600 3%) 2.5143]\n",
            "Whe he ou arl mungst rd or me t r trillent sthis mize, s.\n",
            "\n",
            "He we tis m o th cethit f t metit an, t the \n",
            "\n",
            "[0m 21s (700 3%) 2.4497]\n",
            "Whinde ofais pr manou s t, minds thay borefay histh wos\n",
            "JUKIOfino EThen at ar th anngswis COMusathandi \n",
            "\n",
            "[0m 24s (800 4%) 2.4312]\n",
            "Whirth I Ancoun ond ofr ssisst ngoou foy t tod\n",
            "Fo s pit h thoffou ssithey ad y man mellfis of th'lllin \n",
            "\n",
            "[0m 26s (900 4%) 2.4587]\n",
            "Whotinthotherale tusit anersheamieryomerir\n",
            "To thereaingar as, s.\n",
            "Tothonaver CHULUKI ad ckis y d n he t \n",
            "\n",
            "[0m 30s (1000 5%) 2.4261]\n",
            "Whald w m of n g, d, ll mat of aricealy tosouleer is ha t the aus st er derear t top ar wout al augero \n",
            "\n",
            "[0m 33s (1100 5%) 2.4808]\n",
            "What\n",
            "ARO\n",
            "\n",
            "And the,\n",
            "Torep, methinyopourprgh'Tomere\n",
            "\n",
            "TIVI ler gasityorratourl, thotises pro waturay wima \n",
            "\n",
            "[0m 36s (1200 6%) 2.4409]\n",
            "Whor IOLAnke\n",
            "t he nt ll ho d te\n",
            "CEN:\n",
            "ARoof han onrrou anthomar ho wacene h wisunee o t' y tares hay,\n",
            "\n",
            " \n",
            "\n",
            "[0m 38s (1300 6%) 2.5236]\n",
            "Whende aghar mit me br, t m nthersul itsand me as ou'de us milis,\n",
            "\n",
            "BENCoisish wianthe meralenthit nd,  \n",
            "\n",
            "[0m 42s (1400 7%) 2.4747]\n",
            "Whed t tor four wongen of s y e d mes weathe n he ss awie e! atr tre IOLA mar y t gld:\n",
            "I yore s in w f \n",
            "\n",
            "[0m 45s (1500 7%) 2.4687]\n",
            "Whes oul thas y thran stoe d IN t:\n",
            "\n",
            "TOLAll dshendode by I woughan:\n",
            "\n",
            "\n",
            "I hes de h.\n",
            "\n",
            "\n",
            "Houraknd whus stld  \n",
            "\n",
            "[0m 48s (1600 8%) 2.4547]\n",
            "Whail mus hachis, I or taveag!\n",
            "By ce cou, h mys s; I hathis hayove nthervess fothang, ome gon's\n",
            "Won,\n",
            "A \n",
            "\n",
            "[0m 50s (1700 8%) 2.4780]\n",
            "Whe disun and oul; s herethegrdanis chepre IXENGHe's ormist y al is I s fotoof war lde s cll whif wey  \n",
            "\n",
            "[0m 53s (1800 9%) 2.4856]\n",
            "Whany, EORO:\n",
            "\n",
            "Wis d y wes me h he.\n",
            "IALowouprorit?\n",
            "\n",
            "I thenire ss hererto temstuco kinouron: thags ste t \n",
            "\n",
            "[0m 57s (1900 9%) 2.4953]\n",
            "Whalese!\n",
            "KENA:\n",
            "bellurivelingurinene thenouray berceroncont we co he here t Vio thee,\n",
            "\n",
            "Whis ce noullls  \n",
            "\n",
            "[1m 0s (2000 10%) 2.4603]\n",
            "Whind rond and I be oure t me begorshere I d ne tlsard he y t s au all ce ouch burs w, t mendend m se  \n",
            "\n",
            "[1m 2s (2100 10%) 2.4507]\n",
            "Whe me, aientryoutert de? fre, f, has sh, thiban ll timatoras; pof s'de nt bouisistithay msor hordisth \n",
            "\n",
            "[1m 5s (2200 11%) 2.4848]\n",
            "Wharered yoresur Go GLa sthinthin.\n",
            "Ano nd our GOxe pled t ong yofe mu mak bun bs, t ly ynarsoues gncis \n",
            "\n",
            "[1m 9s (2300 11%) 2.4134]\n",
            "Why, f\n",
            "JUSein s, caino'd thomonche oo t sh d t fe it co-athe, a thain moncavofan!\n",
            "LUS:\n",
            "LAThent fe.\n",
            "\n",
            "Th \n",
            "\n",
            "[1m 12s (2400 12%) 2.4581]\n",
            "Whe aspt f tiliallisares he besaromy, heime r s\n",
            "Fowingryor ave er the mel m alemasprithil? t ne tinard \n",
            "\n",
            "[1m 14s (2500 12%) 2.4788]\n",
            "Whint akere th an fathiche tho ondem he hit, yo, mug sowat st wirshor s the besooly s t ghend min.\n",
            "G m \n",
            "\n",
            "[1m 17s (2600 13%) 2.4303]\n",
            "Wherom.\n",
            "Tout ars nde sth pan this we byowis wou slll chorsthe f\n",
            "BUThanof sur thil the y heno de, julis \n",
            "\n",
            "[1m 21s (2700 13%) 2.4637]\n",
            "Whif ig;\n",
            "Hond anele the mplecche mis d, omofok heyouly d me:\n",
            "Thaketoueapan me orear m s thin achowe My \n",
            "\n",
            "[1m 24s (2800 14%) 2.4666]\n",
            "Whs hthe\n",
            "Wiereathethererdstha mu surer l gis,\n",
            "Ses,\n",
            "Thind o be\n",
            "\n",
            "BICETIndord mef my he fre t RYo w bowar \n",
            "\n",
            "[1m 26s (2900 14%) 2.4926]\n",
            "Wher bed as a heat tildinthane to; ble bran.\n",
            "TILat, t f bushe whell amarshyoushad ller? owiere fo, ari \n",
            "\n",
            "[1m 29s (3000 15%) 2.4570]\n",
            "Whas me ce s couged nd thilo, ts:\n",
            "\n",
            "Wh spsis t t vidoore, t wheses:\n",
            "IORIfe hak, at ds fimyot filis is a \n",
            "\n",
            "[1m 33s (3100 15%) 2.4938]\n",
            "Wh y s d.\n",
            "War, lord sesort ' loolor:\n",
            "OL:\n",
            "\n",
            "F hed t at st Myof m s che ds h thintoso as, calours me fra  \n",
            "\n",
            "[1m 36s (3200 16%) 2.4561]\n",
            "Wh t:\n",
            "Sang avinte thand I'ss, wit lllo co dre s, witobred mutou e ancond,\n",
            "IOLARof those d avend, me\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "[1m 39s (3300 16%) 2.4702]\n",
            "Why do he mat, d s thour herre bll ig I tresemeatheco thangs ce, fed thicoud d y aneleysar offut wise  \n",
            "\n",
            "[1m 41s (3400 17%) 2.3992]\n",
            "Whove hes,\n",
            "\n",
            "MNRAnd t t hiss h her pie cr 'l the trin sind sus d oory be t tre athildeane Set a thefe a \n",
            "\n",
            "[1m 44s (3500 17%) 2.4512]\n",
            "Wh t s my.\n",
            "Bu te ouren bede arongin t trar:\n",
            "D It t my I l as:\n",
            "Whene t then ino than an ancind;\n",
            "LAntot  \n",
            "\n",
            "[1m 48s (3600 18%) 2.4673]\n",
            "Whe yopet r hine hished mend u y ind thind merand, wiunerr o myonngsththit corins candoy je I acheth h \n",
            "\n",
            "[1m 51s (3700 18%) 2.4756]\n",
            "Whondr ten me malld!\n",
            "Thary y alins brean s he my isth I so sth pr t thrverunt theee pshed lil manchinc \n",
            "\n",
            "[1m 53s (3800 19%) 2.4426]\n",
            "What ang acaman s us;\n",
            "MI tu ach n wor d h mp ie glan a\n",
            "G he the I bl t h for thang, wanor tors thanorf \n",
            "\n",
            "[1m 56s (3900 19%) 2.4323]\n",
            "Whar th yorere t s idethind ar seat toucknghes, prais bef tlalountan me t the a Whelf wnthore he pe s. \n",
            "\n",
            "[2m 0s (4000 20%) 2.4318]\n",
            "Whin muraron cersourd S:\n",
            "Yoray cesand m thoupe,\n",
            "Ther'the omy,\n",
            "Whad ave se ping thet anondente, awsthar \n",
            "\n",
            "[2m 3s (4100 20%) 2.4804]\n",
            "Whof be the thithas s? ik IO:\n",
            "\n",
            "LIUMAs h and ime hingourers it tr.\n",
            "I mad, beaus tyose y har thimy bendi \n",
            "\n",
            "[2m 5s (4200 21%) 2.4864]\n",
            "Whine a le od h byon ofinowhey rothesertiryorotharmerd merroular Foome dorn th so fath orer are casowo \n",
            "\n",
            "[2m 8s (4300 21%) 2.4109]\n",
            "Whathe bum, es her my tinserend tod f llind wishy EO:\n",
            "Be t haw by twaiveasis, t as bet?\n",
            "\n",
            "MENENGr mesth \n",
            "\n",
            "[2m 12s (4400 22%) 2.5658]\n",
            "Whe staketha t f macales hed messhans uthis w;\n",
            "\n",
            "PAnd Cosorue,-arwaris, ieras s m haifar so.\n",
            "wo our t\n",
            "\n",
            " \n",
            "\n",
            "[2m 15s (4500 22%) 2.4098]\n",
            "Wh wiste thatoth heda su hothefurderathateenere,\n",
            "'s tead be hitence e pour han soshew to sthe, hirer y \n",
            "\n",
            "[2m 18s (4600 23%) 2.5321]\n",
            "Whend s machis.\n",
            "Tothise bandrithit se fisthefeant, me mu ak thenker y, y f tif r oiker, wind g taves i \n",
            "\n",
            "[2m 20s (4700 23%) 2.3943]\n",
            "Whed trind n.\n",
            "\n",
            "\n",
            "\n",
            "O:\n",
            "And y,\n",
            "ONEd mes thio andoe Bunid he myor:\n",
            "Anod maresthe\n",
            "Anrd If we owick!\n",
            "F t cthe \n",
            "\n",
            "[2m 23s (4800 24%) 2.4461]\n",
            "Whabe rdith\n",
            "\n",
            "Thithe.\n",
            "Yo fos t he ar,\n",
            "NGourwo f d lend nourcom ases che t foun se th is y pall mayond m \n",
            "\n",
            "[2m 27s (4900 24%) 2.4608]\n",
            "Whea brerdes mulin t y\n",
            "An d sace?\n",
            "UCES: ire cod maid my thovend mericoute prsen muthailin g GUSoves ir \n",
            "\n",
            "[2m 29s (5000 25%) 2.4859]\n",
            "Wh.\n",
            "Theso anded f the't tise k, f s, he, I s henar, gmstomaithen grichenone un bene hannowofar ale r a \n",
            "\n",
            "[2m 32s (5100 25%) 2.4291]\n",
            "Wh itherealllo stheerrur lis INGOLI mat lst\n",
            "\n",
            "K:\n",
            "Th:\n",
            "I t.\n",
            "A:\n",
            "Whasthighakll.\n",
            "Her fr\n",
            "\n",
            "HORE:\n",
            "\n",
            "TERORI ielt  \n",
            "\n",
            "[2m 35s (5200 26%) 2.5196]\n",
            "Whar weoisende angend s angand t w, ge mendeegh;\n",
            "Murnge wit onge th thes brirashan ave ar, the ane imm \n",
            "\n",
            "[2m 39s (5300 26%) 2.4687]\n",
            "Whis our s,\n",
            "Thou burntout col, t nce f ind fabld gind ass tlarisere ay,\n",
            "wher is m.\n",
            "Ankeamelotl wath ar \n",
            "\n",
            "[2m 41s (5400 27%) 2.4819]\n",
            "Wheere s hide'd oond t athenelalond akee twisinoo d f d brt mat chale cereves mom; Vo, asert me ng y i \n",
            "\n",
            "[2m 44s (5500 27%) 2.4747]\n",
            "Wher mp t sureass t the?\n",
            "\n",
            "BUMESie womomead the on windyoofopan u y,\n",
            "DI sthe;\n",
            "THad,\n",
            "Und Bedend th e y.  \n",
            "\n",
            "[2m 47s (5600 28%) 2.4779]\n",
            "Whormacelardes os w slat t brar d dyowishis won wricresangath fowiore be nd f tasatod I alorke! po pad \n",
            "\n",
            "[2m 50s (5700 28%) 2.4823]\n",
            "Whtofo sthofollid y D thar?\n",
            "Thand fo u y thatheverier, EThorthed fe itend blend s f deththerepet his k \n",
            "\n",
            "[2m 53s (5800 28%) 2.4874]\n",
            "Whide l thorn bereanowheporsertccks, ngivey at wast bl arstou s hor orsang th\n",
            "\n",
            "T:\n",
            "TINon thatherby nnow \n",
            "\n",
            "[2m 56s (5900 29%) 2.4518]\n",
            "Whe per sshe t send getheshay IOLAne INond af pan d th beetthen hot pe tinolu ptharero CHAPENSINancr a \n",
            "\n",
            "[2m 59s (6000 30%) 2.4516]\n",
            "Whessert aingr oun htharst he te s e;\n",
            "Anooriveat ith d thimu, ppimad, bir st hathare othathamachay t h \n",
            "\n",
            "[3m 2s (6100 30%) 2.4716]\n",
            "Whallersopanopuraly f thot ouril hy t,\n",
            "My ane manck IOL:\n",
            "S:\n",
            "\n",
            "\n",
            "TH:\n",
            "The hiran at t tome disoulld ce yona \n",
            "\n",
            "[3m 5s (6200 31%) 2.4373]\n",
            "Whore; dingrdas he.\n",
            "LENVI hil lfe cll ar win ou RI t s tourt s w ear an in poly Muep wabeds onorsearan \n",
            "\n",
            "[3m 8s (6300 31%) 2.5355]\n",
            "Whe ndse the aventepr\n",
            "THO:\n",
            "JUCHooure, th chere swhe yo imend menthar one, sthes me me me sprss of!\n",
            "\n",
            "ha \n",
            "\n",
            "[3m 11s (6400 32%) 2.4495]\n",
            "Why thesthand sus fanthithetecous y y lou ad thenow me t s ouse, t\n",
            "Tous f s same ct tesicou thare th a \n",
            "\n",
            "[3m 14s (6500 32%) 2.4726]\n",
            "Whirno torer t we her lor wathe tou watote talerive DUSS:\n",
            "Whavis, heseean at, arthin ts t\n",
            "I falisu sh  \n",
            "\n",
            "[3m 18s (6600 33%) 2.5320]\n",
            "Wheret my\n",
            "Fou IARE:\n",
            "Whale t f be RIShaforimars.\n",
            "YO:\n",
            "MANGo.\n",
            "MI Gere\n",
            "t wighat IS ard ie d y maro herd it \n",
            "\n",
            "[3m 20s (6700 33%) 2.4765]\n",
            "Wh:\n",
            "Siord totord far s whee, winofrofor mat u Wheso hinge d henofo isetray war s pean heroury t un g;\n",
            " \n",
            "\n",
            "[3m 23s (6800 34%) 2.5081]\n",
            "Whes, thain n o t thield t toon:\n",
            "Tour bes ars cheshe me br LO, ursthe and.\n",
            "\n",
            "\n",
            "IOUS:\n",
            "An pous gmarje at\n",
            "Y \n",
            "\n",
            "[3m 26s (6900 34%) 2.4917]\n",
            "Whant ar'se ou My bur ar st talar tsshither t thionghor, win arre m, ly, ethed ilyofay thempu tsutare? \n",
            "\n",
            "[3m 29s (7000 35%) 2.4520]\n",
            "Whe f ser y foth mean f atoost.\n",
            "\n",
            "TERT:\n",
            "Yomand mer.\n",
            "AS:\n",
            "\n",
            "Torinres, Thie ngherllan at I baneng myowind m \n",
            "\n",
            "[3m 32s (7100 35%) 2.4675]\n",
            "Whak, blowhe angr,\n",
            "Whagrd anthe ben f;\n",
            "Whesth tht t: whirour win he wrthit les wel, hagong withil I to \n",
            "\n",
            "[3m 35s (7200 36%) 2.4609]\n",
            "Wh onind ly le,\n",
            "\n",
            "Wenthise brelind age G henk, whivere n angur h;\n",
            "\n",
            "\n",
            "Fande owothe mf f renis h aveantine \n",
            "\n",
            "[3m 38s (7300 36%) 2.4255]\n",
            "Whee t lly alles d h t mend mmeakieerdis,\n",
            "Th t t ayoint, that ar.\n",
            "A r-ld,\n",
            "The's r; ite mushed and mert \n",
            "\n",
            "[3m 41s (7400 37%) 2.4606]\n",
            "Whives aros th pe y t ie ous d o anorls merer cal d w mouree inderve t w then thirele tr'd mbr har the \n",
            "\n",
            "[3m 44s (7500 37%) 2.5076]\n",
            "Whis m thoun me hand t r t.\n",
            "\n",
            "No hy wem shasilatombaill lacoverul ngrean at forovens beothe imoullitori \n",
            "\n",
            "[3m 47s (7600 38%) 2.4208]\n",
            "Whal spst w ofove:\n",
            "\n",
            "\n",
            "\n",
            "Sou an ms bemy thilloue:\n",
            "AMENowourthepoct t s p?\n",
            "Thealang grpo's w oncrdigso tha \n",
            "\n",
            "[3m 50s (7700 38%) 2.4588]\n",
            "Whor he ago ue thetrtoupr ashis t o ore benyochar pr spiseree moure, an ave sthend o qutit histind m m \n",
            "\n",
            "[3m 53s (7800 39%) 2.4545]\n",
            "Wharay nd ind th tisendou s;\n",
            "Bue lis:\n",
            "I'd no f thame may ourgonch yopis th t, al verervilas Grerecare  \n",
            "\n",
            "[3m 56s (7900 39%) 2.4464]\n",
            "Whavesu e wothent he athestheat\n",
            "Pes ser SARUTHecy\n",
            "To'dim s m the itor m fowore f the,\n",
            "\n",
            "LONT:\n",
            "Bud, mive \n",
            "\n",
            "[3m 59s (8000 40%) 2.4734]\n",
            "Wheare gherlesecheisillind wh h bent aimoomeparntouthee crupar t thowong tor istow teas certhar hears  \n",
            "\n",
            "[4m 2s (8100 40%) 2.4361]\n",
            "Whay I s, t r har melle my geango f wet nd prthad yey fit tinderon we se h thille o foupind y, hisppuc \n",
            "\n",
            "[4m 5s (8200 41%) 2.5058]\n",
            "Whent hirn d, u ane, myeamors cthilofan at he wndolayoutopr marous ss follofoulistele bldurethirust wi \n",
            "\n",
            "[4m 8s (8300 41%) 2.5127]\n",
            "Whiod fowask fre harurthousldowathat.\n",
            "AMan, f anine yort t ouroun? thes and\n",
            "And? thasd theane cked out \n",
            "\n",
            "[4m 11s (8400 42%) 2.5055]\n",
            "Whathe fe heve the yon merd orer mor.\n",
            "\n",
            "Ay ck ofestheryotong w fand wr inshitheprdow y is cle de houpur \n",
            "\n",
            "[4m 14s (8500 42%) 2.4938]\n",
            "Wh me w ghawind ayrsssatheweere aisthe we breas thenyomatheat heprorsither wou tce le y eacoff:\n",
            "\n",
            "\n",
            "S:\n",
            "W \n",
            "\n",
            "[4m 17s (8600 43%) 2.4837]\n",
            "Whech see we be seealofambry, lingu, care! fug ande k thanour are velave thtande d betou anththe wh so \n",
            "\n",
            "[4m 20s (8700 43%) 2.4954]\n",
            "Wherin of\n",
            "To thavere co p pre thal f thano st thecrser har the d I f y tes. belouthis iseretr fof cowi \n",
            "\n",
            "[4m 23s (8800 44%) 2.4822]\n",
            "Wh ole, w ichegowitho s s of berrby indsas ad haverind, d, mpl ou hised athencer thithimach thearese y \n",
            "\n",
            "[4m 26s (8900 44%) 2.4546]\n",
            "Wharso spl d d weetisithitthelerey h.\n",
            "BE:\n",
            "MERDULLY:\n",
            "\n",
            "\n",
            "KESA alek are t meis y\n",
            "\n",
            "\n",
            "Ane\n",
            "TES:\n",
            "IONI pal m, hi \n",
            "\n",
            "[4m 29s (9000 45%) 2.4503]\n",
            "Whorerey thad weste blast histhave.\n",
            "Theathat sthag, intut hes, ar hothors bembestherde thithin t shile \n",
            "\n",
            "[4m 32s (9100 45%) 2.4277]\n",
            "Whe d sen aithendowore y ty orarsce herrtho nd s wel\n",
            "Roondigr w juteat midisus hin'llisen ppare bes, m \n",
            "\n",
            "[4m 35s (9200 46%) 2.4934]\n",
            "Wh engomes m soulackend peas are ame hathayoonk therefedobenorthalser ntld ben chepeer bere betieng is \n",
            "\n",
            "[4m 38s (9300 46%) 2.4725]\n",
            "Whe we see hapoutheashisstof, pt fo ie ledomy yererd I rg,\n",
            "\n",
            "CHas takereerero I is are, agin oous mand  \n",
            "\n",
            "[4m 41s (9400 47%) 2.5298]\n",
            "Whe l IO:\n",
            "Yo te.\n",
            "\n",
            "Y d dontho INoth e,\n",
            "\n",
            "\n",
            "A s tcere miged'd therme bandincre\n",
            "I ave th nd pre ws the I as \n",
            "\n",
            "[4m 44s (9500 47%) 2.4567]\n",
            "Whe By at atwind he wille alldoune thene be foncanou t hero d ichenares al EThakinghan YOLORE mere s i \n",
            "\n",
            "[4m 47s (9600 48%) 2.5047]\n",
            "Whatot whe thes d hive I wenounowe shay l mar n, mand?\n",
            "\n",
            "\n",
            "w,\n",
            "'st thtingswnd pran y can g berordeigen, t \n",
            "\n",
            "[4m 50s (9700 48%) 2.5165]\n",
            "Whest.\n",
            "fowoveesit s tor sthinghan e lle bud bof ly ighotwaraighethyo avo an!\n",
            "\n",
            "O: masteno,\n",
            "Mouthim t do \n",
            "\n",
            "[4m 53s (9800 49%) 2.4555]\n",
            "Whithendind and me s wese nanges?\n",
            "RIUCLond mar t hest t, alopr wougricay atisthithe t anio isthigise a \n",
            "\n",
            "[4m 56s (9900 49%) 2.4605]\n",
            "Whe ise he hicoreve me p'ss bushouryorve held bre stf t th thalale thanourcyowe me ho d omy whesee iga \n",
            "\n",
            "[5m 0s (10000 50%) 2.4681]\n",
            "Whix hepe s as omy.\n",
            "\n",
            "The me whon, s I s prere t ofouthon.\n",
            "\n",
            "TIUMI ise homy, nd s,\n",
            "LIfon seaknd ouet tho \n",
            "\n",
            "[5m 2s (10100 50%) 2.4358]\n",
            "Whe ad therint\n",
            "\n",
            "ORTor msouo toutaryon\n",
            "\n",
            "A:\n",
            "\n",
            "Whofis as,\n",
            "I:\n",
            "TE pem hanferenontha od t che k.\n",
            "\n",
            "\n",
            "Bu y det f \n",
            "\n",
            "[5m 5s (10200 51%) 2.5261]\n",
            "Wha h, s\n",
            "HES:\n",
            "\n",
            "We cr ff thy blllin t n sthe,\n",
            "slon thiesthe'd d\n",
            "Se mor thand s angr.\n",
            "DUSun sensthe aiea \n",
            "\n",
            "[5m 8s (10300 51%) 2.4238]\n",
            "Wheletheener, tour, wongs\n",
            "Anoun s m t tt th the.\n",
            "ARI t\n",
            "Nur whind f g byind sond ffunde.\n",
            "I:\n",
            "Gr tou he E \n",
            "\n",
            "[5m 11s (10400 52%) 2.4727]\n",
            "Whe lisbes that fown d wis ges llllour har.\n",
            "The af o feng ICAnf anpr, mesteend fralivil s he war omani \n",
            "\n",
            "[5m 14s (10500 52%) 2.4598]\n",
            "Why th r ir thate sthend ie hounouthath thard arif her beevee theadreerd y mad\n",
            "A thorieruronoue te se. \n",
            "\n",
            "[5m 17s (10600 53%) 2.5233]\n",
            "Whad thelee yos the:\n",
            "Ale any hor the thenifrerers t bere, the bresthithat, thim ththedoutithand the ad \n",
            "\n",
            "[5m 20s (10700 53%) 2.4177]\n",
            "Whar foo t h isor rd ber me d thed be od stathe.\n",
            "BUCore, ayore\n",
            "\n",
            "\n",
            "\n",
            "The, tor ary the II you s naleache s \n",
            "\n",
            "[5m 23s (10800 54%) 2.4918]\n",
            "Whithe s me l wanenchis allf s f t fo f hor t s m, moore s,\n",
            "TRe se,\n",
            "\n",
            "KIV: be n thaine ci'towin, t, a b \n",
            "\n",
            "[5m 27s (10900 54%) 2.5290]\n",
            "When ay en'ereas aupodoo that whatoug 'oreron f he is me ath wis t thelll is wnhe wille fon my ato cha \n",
            "\n",
            "[5m 29s (11000 55%) 2.4784]\n",
            "Whaio s no wethy g an:\n",
            "INONCONTorone sthe the has mogs sthe wesed io thande pr y, averpall t mf the pl \n",
            "\n",
            "[5m 32s (11100 55%) 2.4788]\n",
            "Wher the ghancicoray, ke bur, s heromedeay momomyes mear thay theco sat gn toucore h y to t wind I y a \n",
            "\n",
            "[5m 35s (11200 56%) 2.5080]\n",
            "Whis heours he m tinche il inof thaninatom;\n",
            "STh beatordd th.\n",
            "Antithiefaitinge g ico nd s heave ithe.\n",
            "Y \n",
            "\n",
            "[5m 39s (11300 56%) 2.5110]\n",
            "Wh to ffre agoul mel tho me bit ICHisor an a ise, as; f s d t o ms ond illlleru hefelas s cespake moou \n",
            "\n",
            "[5m 41s (11400 56%) 2.5452]\n",
            "Whan a hy hin anowigeed there an f th tonde anticeshere pr s; cheounor the it fthond ie theroure and f \n",
            "\n",
            "[5m 44s (11500 57%) 2.4442]\n",
            "Whe, ffase IOLE:\n",
            "The weld men l y mike, y me thist eatlint O: is,\n",
            "Fairy we wind-aked ther beasiered at \n",
            "\n",
            "[5m 47s (11600 57%) 2.5151]\n",
            "Whavy touche mpe ommod bewaldusoy\n",
            "\n",
            "DUK: t\n",
            "me anis ored I mes goul the hane t I ofreres I:\n",
            "AMur's le ho \n",
            "\n",
            "[5m 50s (11700 58%) 2.4453]\n",
            "Wham g tlimaste s:\n",
            "\n",
            "Tore Com ck, sind t my s bo br e.\n",
            "\n",
            "\n",
            "ORGo in wis GO:\n",
            "Wiste on nd s, sere res imy in \n",
            "\n",
            "[5m 54s (11800 59%) 2.4869]\n",
            "Whitathikiche\n",
            "Ler hise\n",
            "My o gherenty lld to'th d;\n",
            "IVow.\n",
            "II mout t te our an ted thabeerin her thint pr \n",
            "\n",
            "[5m 56s (11900 59%) 2.4992]\n",
            "Whe.\n",
            "\n",
            "\n",
            "And mars w the, favorn ly iout m y mer ware nd e l n whit I dlang 'se wincavome heted, mathalic \n",
            "\n",
            "[5m 59s (12000 60%) 2.4875]\n",
            "Wh omel he t y herifooupr AThabance trind t sthourin'thyol' foa merd Inor heathe f mand than il thoret \n",
            "\n",
            "[6m 2s (12100 60%) 2.4436]\n",
            "Whand sound\n",
            "LIthurd\n",
            "HAspe; her y thene msty merd me t ingbyorast anome shof me my, t\n",
            "IS:\n",
            "\n",
            "\n",
            "I stiny hou \n",
            "\n",
            "[6m 6s (12200 61%) 2.4855]\n",
            "Wharethin ch arethele thedour tes, by n ald m s merving s a t, sestheel ur I he'e je y bes, our t that \n",
            "\n",
            "[6m 8s (12300 61%) 2.4887]\n",
            "Whent thereplllal gersu yo me cay; t y areante e y IO:\n",
            "The be te ie Mut urourleronknge t me.\n",
            "\n",
            "\n",
            "Hasedr  \n",
            "\n",
            "[6m 11s (12400 62%) 2.4226]\n",
            "Whe maro bed and ourer s isothous GLE trorr ise y thepre tove nd ws my cales her. mawe ho ane llis hre \n",
            "\n",
            "[6m 14s (12500 62%) 2.4590]\n",
            "Whesithe platenourethioouse\n",
            "Y:\n",
            "BELAnd llo it peif ad her top st tithealo thet hitot,\n",
            "cin pllll heim it \n",
            "\n",
            "[6m 18s (12600 63%) 2.4243]\n",
            "Whathell ad te m, man yser hos t whyothourr lean mak at bes t ws-d sere hilk, beave.\n",
            "NRD thes s pur t. \n",
            "\n",
            "[6m 20s (12700 63%) 2.5129]\n",
            "Whenous ther wis tha Whyowhame ise thethen masowand.\n",
            "\n",
            "\n",
            "Land ano wathe fl's y,\n",
            "\n",
            "And th, den oweat as H: \n",
            "\n",
            "[6m 23s (12800 64%) 2.5214]\n",
            "Whengronor LO:\n",
            "\n",
            "NG y r me!\n",
            "S:\n",
            "Hed suathean rallom his s, t t\n",
            "ADI tu thave.\n",
            "Ifff g.\n",
            "HI did if sidandor  \n",
            "\n",
            "[6m 26s (12900 64%) 2.4506]\n",
            "Whe tal: to ter w for perod fl wheris.\n",
            "Te no chare, he:\n",
            "PENTh byon my he hominout tas go por y thean w \n",
            "\n",
            "[6m 30s (13000 65%) 2.4528]\n",
            "Whellan purar ire st t chomathe te we s he ilinger ienghis that, ougesu werele bale pine, wnd lyouill  \n",
            "\n",
            "[6m 32s (13100 65%) 2.4306]\n",
            "Wheancke thele mes t mowand he t d burve on,\n",
            "I wind teld anast athe me hallore he tendw bereronoun wou \n",
            "\n",
            "[6m 35s (13200 66%) 2.5015]\n",
            "Whay feather'sstupisat weried s ound me the, wig, hithen\n",
            "INouthike ourelof f f fours\n",
            "Buche feron nd sc \n",
            "\n",
            "[6m 38s (13300 66%) 2.4346]\n",
            "Wh sioveacef, budrer-\n",
            "ICENGofomy I lar: iglofr gha tuseof.\n",
            "HEYo or I wat s, in stedll ind ke n ich IXE \n",
            "\n",
            "[6m 41s (13400 67%) 2.5585]\n",
            "Whe?\n",
            "The o fo, y po r s t y theisind he t ongasepatealllpesous, d tamageais du f nkeelo lorou ne ousom \n",
            "\n",
            "[6m 44s (13500 67%) 2.4472]\n",
            "Whusele:\n",
            "ANARES:\n",
            "Bavecay nsharey thale soteate s angutho!\n",
            "TA t hig lacode, st s, y s m t oos hith enou \n",
            "\n",
            "[6m 47s (13600 68%) 2.4632]\n",
            "Wh mend ssthithathould. py bee omande pe d, sithas er ome u thar sadounche f wemandw h ce pofre sild s \n",
            "\n",
            "[6m 50s (13700 68%) 2.4691]\n",
            "Whingue bspe?\n",
            "O:\n",
            "Busthe\n",
            "Whu ounee I Ofay se o merme bu as sth thist mengorthy:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ANINCELIO,\n",
            "Hean mee \n",
            "\n",
            "[6m 53s (13800 69%) 2.4806]\n",
            "Whindeland myor breshar irs bid MENI s wor t ay te grtrcoseleale counouthe winckit an e we,\n",
            "Whane. the \n",
            "\n",
            "[6m 56s (13900 69%) 2.5375]\n",
            "Whe, serd?\n",
            "CORUCERARUCANABe when we, gofaroprs nfond ore KENThant, hin ce me s t s w\n",
            "Ty\n",
            "\n",
            "\n",
            "EN a whe atr \n",
            "\n",
            "[6m 59s (14000 70%) 2.4480]\n",
            "Whigeethes IS it\n",
            "IOLAshigntur s acchacisthag tha\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Wherealorerd me scknd ncere hand saisurd, hend f \n",
            "\n",
            "[7m 2s (14100 70%) 2.5033]\n",
            "Whitharurealit thy tho that in, g,\n",
            "Whepra hanadsinnownd m aitsin and hous, Th grded the, wstheree s tr \n",
            "\n",
            "[7m 5s (14200 71%) 2.5012]\n",
            "Whiers\n",
            "SELYohe toulanchay ton anat de Ase bof thalotuld g meshid rther:\n",
            "\n",
            "\n",
            "Howis\n",
            "\n",
            "JOre th hor s a ad ti \n",
            "\n",
            "[7m 8s (14300 71%) 2.4479]\n",
            "Wheath st m tr on alat heaventherdosthare s n,\n",
            "TI E br, hand tout ughe fatharr g our m s te f antwes n \n",
            "\n",
            "[7m 11s (14400 72%) 2.4798]\n",
            "Wh irema sthe uthey icou m ourelid s o lowan ss\n",
            "R: LI whe s tig d?\n",
            "Whevorurenorel; my weve bll su yowi \n",
            "\n",
            "[7m 14s (14500 72%) 2.4811]\n",
            "Whorin so yo par,\n",
            "\n",
            "Thiferislay wingoulane blit ithous bakethinoure tr r the:\n",
            "HAf it be berd st ard the \n",
            "\n",
            "[7m 17s (14600 73%) 2.3966]\n",
            "Whers hy brs bung, at the d Lomelll be ke han win d ts hay uno qure to wed mo hithe t t bis; had s ale \n",
            "\n",
            "[7m 20s (14700 73%) 2.4255]\n",
            "Whe the whethiche t ather'sthingom fthaburd bert\n",
            "CHom are d sertheerer ongice thourts st the ar ho ila \n",
            "\n",
            "[7m 23s (14800 74%) 2.4660]\n",
            "Wh,\n",
            "Thear t me t tre, t t cyor te the;\n",
            "I thes he t cer thitind sthango merer bofan re\n",
            "NIUCENARUS:\n",
            "O, t \n",
            "\n",
            "[7m 26s (14900 74%) 2.4584]\n",
            "Whoo at e I d ous mishince theane are? trve fe.\n",
            "\n",
            "Torte che ld ono s se he pr, t yotanghe h d hawhate,  \n",
            "\n",
            "[7m 29s (15000 75%) 2.4990]\n",
            "Whe kierou be tiour inofowindal aneind bur whed we w e lloucathealf mar:\n",
            "UKI goughoves thecharcoube h  \n",
            "\n",
            "[7m 32s (15100 75%) 2.4587]\n",
            "Whor byome thiteenoar hese s;\n",
            "Athearee t fond s cecech, tlede hes dites h y, hithatheatoreandoupr.\n",
            "NG  \n",
            "\n",
            "[7m 35s (15200 76%) 2.4437]\n",
            "Whe at t the thayothathe GO:\n",
            "bllel thik, asthars a nd tothias hingo!\n",
            "\n",
            "\n",
            "Bu ber the ou, he?\n",
            "TENGRAnd ath \n",
            "\n",
            "[7m 38s (15300 76%) 2.4063]\n",
            "What f aveno s pir is, en:\n",
            "For rar naco or hed nowiseleisit theanen me wit wours y Bofiface:\n",
            "Susu owar \n",
            "\n",
            "[7m 41s (15400 77%) 2.4612]\n",
            "Whathan brurs withimpoug f amot on m th blepa dssstte by INThe hivave mee t\n",
            "Gokneres?\n",
            "\n",
            "\n",
            "Me f prnceend: \n",
            "\n",
            "[7m 44s (15500 77%) 2.5019]\n",
            "Whivengr t.\n",
            "\n",
            "\n",
            "O, mbomoigan thisesen cit 'dwind tlfoury bu wis ice heand he, lold wshesthot ty wosthe t \n",
            "\n",
            "[7m 47s (15600 78%) 2.4714]\n",
            "Wheren and mer t d s heate win s in my d inense t!\n",
            "yonge\n",
            "\n",
            "\n",
            "Cor owere avionthe ncloviemy br meanowotris \n",
            "\n",
            "[7m 50s (15700 78%) 2.4724]\n",
            "Wher yand onghe skere om? ealde IUSERonge.\n",
            "\n",
            "\n",
            "I thetimoughyodin pawesth ne whand ince be alis an t, ste \n",
            "\n",
            "[7m 53s (15800 79%) 2.4868]\n",
            "Whagle is pevin\n",
            "That mestht ld bu pee I, nchourd igh t hiod f n chet owis wouling s gncer be is laleor \n",
            "\n",
            "[7m 55s (15900 79%) 2.5340]\n",
            "Wh otheer oream withifof ARKI\n",
            "O:\n",
            "\n",
            "\n",
            "TRURONosere s I str n anthamyon heringrt t d hon alseerd t His hame \n",
            "\n",
            "[7m 59s (16000 80%) 2.5130]\n",
            "Whthof weron plere oresien,\n",
            "Car yotou is cosesomyot thaty s.\n",
            "pelt coit inve an frotheat boun, wndowero \n",
            "\n",
            "[8m 2s (16100 80%) 2.4536]\n",
            "Wh;\n",
            "\n",
            "Hene wr ave walfinte nd alinesom mulde ant\n",
            "Sherar'ther gatharimo bl atr eef wherert,\n",
            "Whe wan mme  \n",
            "\n",
            "[8m 5s (16200 81%) 2.5439]\n",
            "Whe onnd m ave p iseabr my beand\n",
            "\n",
            "\n",
            "Hanged ma othe war, pthewf the mane lllls,\n",
            "MELA olyrig, hothe he s  \n",
            "\n",
            "[8m 7s (16300 81%) 2.4915]\n",
            "Whe cea y atreersonse;\n",
            "CHENSa f funerur oncod ancha and caran te:\n",
            "KI alllererir towillsto ss lout cer, \n",
            "\n",
            "[8m 10s (16400 82%) 2.4670]\n",
            "Wher, youan folly id O:\n",
            "satharke y ke be ave.\n",
            "It pplis t the g y mbritorithe\n",
            "Anqus tofo sep arolfothe  \n",
            "\n",
            "[8m 14s (16500 82%) 2.4653]\n",
            "When hee yominere uthesu h w\n",
            "\n",
            "F he engie IUCO,\n",
            "\n",
            "Ineay k andes ishit Gofout th win ay ill thagomalo oun \n",
            "\n",
            "[8m 17s (16600 83%) 2.4852]\n",
            "Whror plllarar:\n",
            "Hes surowarovane asibu d ca de ow rs 'dg Ined n than stord thaver y bur s surener f be \n",
            "\n",
            "[8m 19s (16700 83%) 2.4688]\n",
            "Whede, mantharje mee werd thourendin amethy ye tst t Cave INEDUSThashury th, wn; mint,\n",
            "Twenthip slldor \n",
            "\n",
            "[8m 22s (16800 84%) 2.4582]\n",
            "Wh t d, he:\n",
            "\n",
            "AMETI:\n",
            "\n",
            "KAn ch ss frotheden thenoude s he CARWAPERONG hitoullyo ll t thesshe meave's ond  \n",
            "\n",
            "[8m 26s (16900 84%) 2.4898]\n",
            "Where g hise, mabloomuld boullllo bu a anousidod ke wingepral is t of berd brbe merin\n",
            "\n",
            "\n",
            "hatha hire hai \n",
            "\n",
            "[8m 29s (17000 85%) 2.4891]\n",
            "Whe l youe I opllesisugreder, bll w Fouay ap oth, t I I be.\n",
            "Yor, llout al lothan,\n",
            "\n",
            "Therduger min my co \n",
            "\n",
            "[8m 31s (17100 85%) 2.4926]\n",
            "Whe o-t br.\n",
            "TESes hit, a f timy RTIClis w ser, wh me'st ith tthasene helimik,\n",
            "irthe!\n",
            "Crusas t pr tathe \n",
            "\n",
            "[8m 34s (17200 86%) 2.4055]\n",
            "Whesthe s sthenet he\n",
            "An s ctotou wintll tus he he spese sean itul tas aratere ingont migucha f wout f  \n",
            "\n",
            "[8m 37s (17300 86%) 2.4494]\n",
            "Whan h the y s achad\n",
            "ANUKINDULoutun st y fr hirtheller lomesshe arepl har s, y s we chewie nf ice lith \n",
            "\n",
            "[8m 41s (17400 87%) 2.4463]\n",
            "Wheaten d coste beardran tuis way chede honthe my d th?\n",
            "\n",
            "D our he hers tound il.\n",
            "MI anowhe,\n",
            "Bo w's we  \n",
            "\n",
            "[8m 43s (17500 87%) 2.5446]\n",
            "Wh me he we d ine ono he an s s we MESAns f where lll hinot ishig co cknce the.\n",
            "AUS:\n",
            "Whathe sin a ws,  \n",
            "\n",
            "[8m 46s (17600 88%) 2.4405]\n",
            "Wholy'desthe irdwese we sut ard n mbur ker, wen sthes,\n",
            "\n",
            "\n",
            "\n",
            "are isosthelo sthandirof bru thitor the and  \n",
            "\n",
            "[8m 49s (17700 88%) 2.4662]\n",
            "Wharo toothe nindingesisageeruthe wastyothy IOUThad ng te wie, houcingr aveno othes ag py mose my ghe  \n",
            "\n",
            "[8m 53s (17800 89%) 2.4311]\n",
            "Whee l met my,\n",
            "\n",
            "Thatithousis he y nce hy mye y onesur iseratin'shimy co k tles cate; win,\n",
            "LI ther's m  \n",
            "\n",
            "[8m 56s (17900 89%) 2.4884]\n",
            "Whey selilat henond t wingea bas thangesineayosef lenckit:\n",
            "It all sthithas d athard f orger t torerend \n",
            "\n",
            "[8m 58s (18000 90%) 2.5149]\n",
            "Whispyous g g.\n",
            "\n",
            "T:\n",
            "Thod, hay pivegonowand sul t t tandenoth llyo the us menersthe s mour ghith s,\n",
            "WART \n",
            "\n",
            "[9m 1s (18100 90%) 2.4264]\n",
            "Whe than y t oneds br narditharet mingothathin atherde t keve atherre latlinouracaken I hatout INCouth \n",
            "\n",
            "[9m 5s (18200 91%) 2.4418]\n",
            "Whe IANGARYoural thanut t.\n",
            "AULINor w, aneshiray th ilelat anou ronco athont! ho all inthy tharin ierar \n",
            "\n",
            "[9m 8s (18300 91%) 2.4762]\n",
            "Whe\n",
            "Wis f is te ath wis ag, I iny ashe th ncono andat ICOFo sueremilly S:\n",
            "NCAUpe\n",
            "SThe y t st he.\n",
            "Y:\n",
            "An \n",
            "\n",
            "[9m 10s (18400 92%) 2.4662]\n",
            "Whinces lounas ous be at od ble'd, kis the,\n",
            "NThe se, s wotot be l, turas opr than bumantoraut her wind \n",
            "\n",
            "[9m 13s (18500 92%) 2.4839]\n",
            "What bun we d win how ba hasey thefrse icel:\n",
            "Youthend y co the n we wnr blll the:\n",
            "Yer ath hem, main st \n",
            "\n",
            "[9m 17s (18600 93%) 2.4566]\n",
            "Whe istharid sild bl sout te, ack'st amourishy yor ay d y rvif:\n",
            "TRI thr nirds mathist rsthe por:\n",
            "I:\n",
            "\n",
            "H \n",
            "\n",
            "[9m 20s (18700 93%) 2.4476]\n",
            "Whern moulofallly I t, mave.\n",
            "SINo?\n",
            "AN thothaucreatit nthace.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "AMy u onkids far lilory s f wecoourer \n",
            "\n",
            "[9m 22s (18800 94%) 2.4420]\n",
            "Wher merat it wheas ne ard;\n",
            "Fot tingeathe the w n ono bend\n",
            "Tat hathas nt t cetht th, we,\n",
            "Thicare hesen \n",
            "\n",
            "[9m 25s (18900 94%) 2.4481]\n",
            "Whaino as ss pon thesey d w hitor t gute ilot hit aly, belatingout tade tean s y it co est thour tholl \n",
            "\n",
            "[9m 28s (19000 95%) 2.4353]\n",
            "Whess s ay whath CE:\n",
            "Mere;\n",
            "Waloug wou hentanguthemer houed ano tr t ard mat:\n",
            "T:\n",
            "Ano,\n",
            "Wh aror arth owee \n",
            "\n",
            "[9m 32s (19100 95%) 2.4523]\n",
            "Whe that lld thands.\n",
            "COxtoul t me s e myeig dome\n",
            "ARUMow s ce,\n",
            "NIO:\n",
            "ABANofatherd ff s: k, t myomied ig' \n",
            "\n",
            "[9m 34s (19200 96%) 2.5161]\n",
            "Whe want, cer'd cey dreands alerer harithell ay acan ad bur ond te d ad; f or ppave hane fonoist wsa t \n",
            "\n",
            "[9m 37s (19300 96%) 2.5294]\n",
            "Whe batore we, the womy my urougurmalo shin beray t vin inon an hest wand s briler oupe!\n",
            "t,\n",
            "\n",
            "Fin w thi \n",
            "\n",
            "[9m 40s (19400 97%) 2.5153]\n",
            "Whie womur,\n",
            "\n",
            "What s aserit thenit in atase t tris.\n",
            "S:\n",
            "S:\n",
            "Anghove s the fl hard,\n",
            "\n",
            "GHANRI whe ive ay ala \n",
            "\n",
            "[9m 44s (19500 97%) 2.4055]\n",
            "Whou yor s hthe heris t, und myouendoodethes p, I gheely:\n",
            "\n",
            "Thenst and an y t?\n",
            "Bund I I bins;\n",
            "E:\n",
            "HORDUS \n",
            "\n",
            "[9m 47s (19600 98%) 2.4777]\n",
            "Whor he d athellshee TI inorlthis stor?\n",
            "IOLERColither, hie ELORANDY w, ds y; aze aste m thar s mawhor, \n",
            "\n",
            "[9m 49s (19700 98%) 2.5134]\n",
            "Whaindinous mers adeeg we\n",
            "THIf s th l merean his s ower\n",
            "TI t.\n",
            "IORED be ne ckis o meard,\n",
            "\n",
            "I arns helllo \n",
            "\n",
            "[9m 52s (19800 99%) 2.4764]\n",
            "Whad pofour toron\n",
            "\n",
            "INCELo f this ve chichicly thave not il po and ssthifothe beatar men, IO:\n",
            "\n",
            "I\n",
            "TI sou \n",
            "\n",
            "[9m 56s (19900 99%) 2.4872]\n",
            "Wh mea t ther;\n",
            "Whe s thee IVareyerthe andre ove benesove crde s f I harmerore e st t m w o tt th be bu \n",
            "\n",
            "[9m 59s (20000 100%) 2.5577]\n",
            "Whoucl ediof so bu haste owh of t les I ld t thif it h n banourso mave O:\n",
            "Whie t'sw\n",
            "Louse the d o blis \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "###Parameters\n",
        "n_epochs = 20000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "hidden_size = 100\n",
        "n_layers = 5\n",
        "lr = 0.005\n",
        "batch_size = 16\n",
        "chunk_len = 80\n",
        "\n",
        "####\n",
        "\n",
        "model = RNN(n_characters, hidden_size, n_characters, n_layers) #create model\n",
        "model_optimizer = torch.optim.Adam(model.parameters(), lr=lr) #create Adam optimizer\n",
        "# Fonction d'erreur utilisée\n",
        "# Fonction de loss adapté pour la classification\n",
        "criterion = nn.CrossEntropyLoss() #chose criterion\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "\n",
        "def train(inp, target):\n",
        "    \"\"\"\n",
        "    Train sequence for one chunk:\n",
        "    \"\"\"\n",
        "    #reset gradients\n",
        "    model_optimizer.zero_grad() \n",
        "    \n",
        "    # predict output\n",
        "    output = model(inp)\n",
        "    \n",
        "    #compute loss\n",
        "    loss =  criterion(output.view(batch_size*chunk_len,-1), target.view(-1)) \n",
        "\n",
        "    #compute gradients and backpropagate\n",
        "    loss.backward() \n",
        "    model_optimizer.step() \n",
        "\n",
        "    return loss.data.item() \n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set(chunk_len,batch_size))  #train on one chunk \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(generate(model,'Wh', 100), '\\n')\n",
        "       \n",
        "\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "392ec37e",
      "metadata": {
        "id": "392ec37e"
      },
      "source": [
        "## Visualize loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "caf419b5",
      "metadata": {
        "id": "caf419b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "cb2cd4b7-df26-4c24-c095-6f8155dfb280"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca798bc9a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eab32c42",
      "metadata": {
        "id": "eab32c42"
      },
      "source": [
        "## Try different temperatures\n",
        "\n",
        "Changing the distribution sharpness has an impact on character sampling:\n",
        "\n",
        "more or less probable things are sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b2273e75",
      "metadata": {
        "id": "b2273e75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197a13fa-d117-4d65-c504-10d28b971f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tebeauk os mont tay fle. sey s,\n",
            "Wist hasthakime denthe ak, acry tothavis mar'd dye h Wheik wo IUSheay\n",
            "\n",
            "DEver.\n",
            "Tharyou ic f brme oonghf r we tho t houaiseghousoortmat\n",
            "CA:\n",
            "CAULUMAULUMoninoroulatour! howh\n",
            "----\n",
            "Thar!\n",
            "\n",
            "FRI t s withe I mincke d\n",
            "Diree youchar.\n",
            "An Lor s fu he berenthe f irout.\n",
            "Th mom OLULO:\n",
            "\n",
            "\n",
            "Yornoryotrere,\n",
            "AThe bureallathilandou s he thither the t.\n",
            "\n",
            "SAnisiotedino herse.\n",
            "Bathoure I bet ages ctoutt\n",
            "----\n",
            "The withe m oulllo he w d f wist are n he lllarean he he we thinghethe fou hile n there mereathisthe as be l d anerithe I alld s as the wango o bres y s win hanon thes athe the winge y angar's thand t t\n",
            "----\n",
            "The an the the ar t t t and ingo t the in s the lle har the for he of t the s t ithare the the t my a the the t the s t and t the t f at, the the the t the the s the the me the ar the an man bllllor the\n",
            "----\n",
            "The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the th\n"
          ]
        }
      ],
      "source": [
        "print(generate(model,'T', 200, temperature=1))\n",
        "print(\"----\")\n",
        "print(generate(model,'Th', 200, temperature=0.8))\n",
        "print(\"----\")\n",
        "\n",
        "print(generate(model,'Th', 200, temperature=0.5))\n",
        "print(\"----\")\n",
        "\n",
        "print(generate(model,'Th', 200, temperature=0.3))\n",
        "print(\"----\")\n",
        "\n",
        "print(generate(model,'Th', 200, temperature=0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc3dea6",
      "metadata": {
        "id": "9cc3dea6"
      },
      "source": [
        "### Improving this code:\n",
        "\n",
        "(a) Tinker with parameters:\n",
        "\n",
        "- Is it really necessary to have 100 dims character embeddings\n",
        "- Chunk length can be gradually increased\n",
        "- Try changing RNN cell type (GRUs - LSTMs)\n",
        "\n",
        "(b) Add GPU support to go faster\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b48332e",
      "metadata": {
        "id": "8b48332e"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rendu prj:\n",
        "BoW\n",
        "\n",
        "Obj : Impact de la chaine du traitement sur les résultats.\n",
        "\n",
        "## Rendu tmes:\n",
        "Pas trop s'étaler sur les deux derniers\n",
        "\n",
        "A rendre pour le 19 mars\n",
        "\n",
        "30%"
      ],
      "metadata": {
        "id": "Ye9Xqu_VNX2e"
      },
      "id": "Ye9Xqu_VNX2e"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}